# services/rag_service.py

from langchain.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_core.documents import Document
from utils.rag_text_templates import build_full_rag_text
from utils.rag_builder import build_and_store_rag
from models.schemas import FullUserProfileSchema 
from LLM_model import generate_answer_from_gemini

CHROMA_PATH = "chroma_db"
embedding_model = OllamaEmbeddings(model="nomic-embed-text")

def generate_user_rag(user_data: FullUserProfileSchema):
    """
    ì‚¬ìš©ìì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ RAG í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ Chroma DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    user_id = user_data.user_details.user_id  # â† ì—¬ê¸°ì„œ ì •í™•íˆ êº¼ë‚´ì•¼ í•¨

    print(f"ğŸ“„ [RAG] ìœ ì € ì •ë³´ ê¸°ë°˜ ë¬¸ì„œ ìƒì„± ì‹œì‘ (user_id={user_id})")
    
    # 1. í…ìŠ¤íŠ¸ ìƒì„±
    rag_text = build_full_rag_text(user_data)
    
    # 2. Document ë³€í™˜
    documents = [Document(page_content=rag_text)]

    # 3. ì €ì¥
    collection_name = f"user_{user_id}"
    build_and_store_rag(documents, collection_name)

    print(f"âœ… [RAG] Chroma ì €ì¥ ì™„ë£Œ: {collection_name}")


def generate_chat_response(user_id: int, question: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ Chromaì—ì„œ RAG ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , Gemini ëª¨ë¸ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    collection_name = f"user_{user_id}"
    print(f"\nğŸ§  [RAG] user_id={user_id} ì§ˆë¬¸: {question}")

    # ë²¡í„° DB ë¡œë”©
    vectorstore = Chroma(
        collection_name=collection_name,
        embedding_function=embedding_model,
        persist_directory=CHROMA_PATH
    )

    # ë²¡í„° ê²€ìƒ‰
    docs = vectorstore.similarity_search(question, k=3)
    print("ğŸ“„ [RAG] ê²€ìƒ‰ëœ ë¬¸ì„œ:")
    for i, doc in enumerate(docs):
        print(f"  {i+1}. {doc.page_content[:100]}...")  # ë„ˆë¬´ ê¸¸ë©´ 100ìë§Œ

    retrieved_text = "\n".join([doc.page_content for doc in docs])

    if not retrieved_text:
        retrieved_text = "ì‚¬ìš©ì ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ ìƒë‹´ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
        print("âš ï¸ [RAG] ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ context ì‚¬ìš©.")

    # Gemini í˜¸ì¶œ
    return generate_answer_from_gemini(user_id, question, retrieved_text)
